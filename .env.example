# ------------------------- Azure Demo -------------------------
# tokens for API access - replace the placeholder values with your actual keys
ANTHROPIC_AUTH_TOKEN=sk-your-anthropic-auth-token

# Azure OpenAI 配置（请替换为你的真实值）
PREFERRED_PROVIDER=azure
BIG_MODEL=gpt-5.2-codex
SMALL_MODEL=gpt-5.2

# 你可以填写完整的 Responses URL，系统会自动提取 base 与 api-version
AZURE_OPENAI_ENDPOINT=https://your.cognitiveservices.azure.com/openai/responses?api-version=2025-04-01-preview
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# 可选：若未在URL中携带 api-version，则使用此值
AZURE_API_VERSION=2025-04-01-preview

LOG_LEVEL=INFO
LOG_FILE=./logs/proxy-%Y%m%d.log
LOG_FILE_MAX_BYTES=10000000
LOG_FILE_BACKUP_COUNT=5
#------------------------- End Azure Demo -------------------------

# Claude + Code GPT Proxy Example Environment Variables
# Required API Keys
#ANTHROPIC_API_KEY=your-anthropic-api-key # Needed if proxying *to* Anthropic
#OPENAI_API_KEY=sk-...
#GEMINI_API_KEY=your-google-ai-studio-key

# Optional inbound auth for this proxy
# If set, clients must send Authorization: Bearer <token>
#ANTHROPIC_AUTH_TOKEN=your-shared-secret

# Optional: Provider Preference and Model Mapping
# Controls which provider (google, openai, or anthropic) is preferred for mapping haiku/sonnet.
# Defaults to openai if not set.
# Set to "anthropic" for "just an Anthropic proxy" mode (no remapping)
#PREFERRED_PROVIDER=openai
#OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Specify the exact models to map haiku/sonnet to.
# If PREFERRED_PROVIDER=google, these MUST be valid Gemini model names known to the server.
# Defaults to gemini-2.5-pro and gemini-2.5-flash if PREFERRED_PROVIDER=google.
# Defaults to gpt-4.1 and gpt-4.1-mini if PREFERRED_PROVIDER=openai.
# These are IGNORED when PREFERRED_PROVIDER=anthropic (models are not remapped).
# BIG_MODEL=gpt-4.1
# SMALL_MODEL=gpt-4.1-mini

# Example Google mapping:
# PREFERRED_PROVIDER=google
# BIG_MODEL=gemini-2.5-pro
# SMALL_MODEL=gemini-2.5-flash

# Example Google with vertex AI auth via ADC:
# PREFERRED_PROVIDER=google
# USE_VERTEX_AUTH=true
# BIG_MODEL=gemini-2.5-pro
# SMALL_MODEL=gemini-2.5-flash

# Example "just an Anthropic proxy" mode:
# PREFERRED_PROVIDER=anthropic
# (BIG_MODEL and SMALL_MODEL are ignored in this mode)

# Optional logging (file logging disabled unless LOG_FILE is set)
# LOG_LEVEL=INFO
# LOG_FILE=./logs/proxy-%Y%m%d.log
# LOG_FILE_BACKUP_COUNT=7
# LOG_FILE_PATTERN=proxy-%Y%m%d.log # Rotated filename pattern (strftime) for daily rollover